# Learn_With_Shubham

## Talks

1. Interpreting the results using Attension Maps

2. Different Types of Regularization
   * Data Augmentation
   * Dropouts
   * L1/L2 Penalty
  
3. Batch Normalization
